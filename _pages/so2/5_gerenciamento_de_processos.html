---
title: "SO2-Gerenciamento de Processos"
layout: default
---
<h1 class="ui header">5. Gerenciamento de Processos</h1>

<h2>Criação e encerramento de processos</h2>

<p class="importante">Ao executar a chamada fork o SO faz uma cópia do processo atual. Para fazer isso, é preciso alocar um novo descritor de processos que, no Linux, chama-se <b><a href="http://elixir.free-electrons.com/linux/latest/source/include/linux/sched.h#L519" target="_blank">task_struct</a></b>. Também é preciso determinar um PID único para esse novo processo, que terá o valor de PPID igual ao PID do processo que executou a chamada, seu pai.</p>

<p>Além do PID, o SO mantém vários identificadores associados a um processo, como ppid, pgid, uid e gid, que indicam o processo pai, o grupo de processo (process group), o usuário e o grupo base associados ao processo. As permissões são herdadas do usuário ao qual o processo está associado, a menos que o arquivo executável tenha o atributo setuid ou setgid, que o fazem herdar os privilégios associados ao dono ou ao grupo do arquivo.</p>

<p>Prioridades, identificadores da política de escalonamento, contadores de uso de recursos, referências a threads associadas ao processo, e outras tantas informações, são mantidas pelo SO na task_struct de um processo. Outras informações importantes incluem o vetor de <span class="importante">arquivos abertos e uma estrutura para tratamento de sinais</span>.</p>

<p class="importante">Como num ambiente multitarefa há um isolamento entre as áreas de memória dos processos, usando memória virtual, é preciso alocar áreas de memória para o processo filho sendo criado. Assim, o SO cria uma nova page table, que será usada pela MMU do processador para traduzir endereços lógicos em endereços físicos. Para acelerar as traduções de endereço, é comum que as informações da page table sejam armazenadas numa memória de acesso rápido chamada TLB (translation lookaside buffer), <span class="duvida">ajustada pelo SO nas trocas de contexto</span>.</p>

<p>Se o processo filho é uma cópia do pai, o SO deve copiar informações do descritor (task_struct) do processo pai para o descritor do processo filho. Também é preciso copiar áreas de memória de código e dados (segmento de dados, variáveis estáticas, heap e pilha). <span class="importante">Para melhorar o tempo de criação de processos, contudo, o Linux usa uma estratégia chamada copy-on-write</span>. Neste caso, o SO apenas copia a tabela de páginas do processo pai para o filho, apontando para as mesmas páginas de memória. Deste modo, se o processo filho terminar em seguida ou se fizer uma chamada para sobrepor sua área de código com a função exec, não houve gasto desnecessário com duplicações de memória. Por outro lado, se o processo filho ou o pai tentarem modificar qualquer página, é preciso gerar uma cópia desta página para o filho antes.</p>

<p>De maneira resumida, o fork cria uma cópia do processo atual. Após a criação, os 2 processos vão para a fila de processos prontos e, quando selecionados pelo escalonador, voltam à execução na instrução seguinte à chamada fork.</p>

<p>A chamada exec mantém o descritor do processo atual, seu identificador de processo, e várias outras informações, mas substitui a área de código e dados, zera a área de pilha e <span class="duvida">ajusta o contexto para a execução do novo processo</span>.</p>

<p>Se um processo é criado com a chamada fork(), como ele termina? Salvo nas condições de erro, em que um processo é terminado pelo tratamento de um sinal (que também pode ser gerado por outro processo), <span class="importante">um processo deve fazer uma chamada explícita ao SO para terminar</span>. Na prática, em programas C, o simples retorno da função main() vai ser tratado pelo compilador com a inclusão de uma chamada da função exit(3). Também é possível terminar o processo chamando explicitamente a função C exit(3), ou a chamada de sistema _exit(2). Nesses casos, o SO termina o processo, liberando os recursos que ele tinha alocado.</p>

<h4>Exemplo</h4>
<pre><code>
  /*
  ** Universidade Federal de São Carlos
  ** Departamento de Computação
  ** Prof. Hélio Crestana Guardia
  ** Sistemas Operacionais 2
  ** Objetivo: Ilustrar o tratamento da condição de saída de um processo filho
  */

  #include &ltsys/types.h&gt
  #include &ltsys/wait.h&gt
  #include &ltstdlib.h&gt
  #include &ltstdio.h&gt
  #include &ltunistd.h&gt


  int main()
  {
  	pid_t pid;
  	int status;
  	int fim;

  	if((pid=fork())==-1) {
  		perror("Erro no fork");
  		// Embora a chamada falhou, não houve um erro na execução do programa
  		exit(EXIT_SUCCESS);
  	}

  	if(pid==0) {	// filho
  		sleep(30);
  		exit(EXIT_SUCCESS);
  	} else {	// pai

  		/*
  		WIFEXITED(status): returns true if the child terminated normally.
  		WEXITSTATUS(status): returns the exit status of the child.
  		WIFSIGNALED(status): returns true if the child process was terminated by a signal.
  		WTERMSIG(status): returns the number of the signal that caused the child process to terminate.
  		WCOREDUMP(status): returns true if the child produced a core dump.
  		WIFSTOPPED(status): returns true if the child process was stopped by delivery of a signal;
  		*/

  		fim=0;

  		do {
  			printf("Pai esperando filho %d\n",pid); fflush(stdout);

  			pid=wait(&status);

  			if(WIFEXITED(status)) {
  				printf("Filho terminou com status %d\n", WEXITSTATUS(status));
  				fim=1;
  			}

  			if(WIFSIGNALED(status)) {
  				printf("Filho terminou terminou com o recebimento do sinal: %d\n", WTERMSIG(status));
  				fim=1;

  				if(WCOREDUMP(status))
  				printf("Filho terminou terminou gerando core dump...\n");
  			}

  			if(WIFSTOPPED(status))
  			printf("Filho foi parado (stopped) com o recebimento de um sinal...\n");

  		} while(!fim);
  	}

  	return EXIT_SUCCESS;
  }

</code></pre>

<h2>Prioridades e escalonamento</h2>

<p>Processos e threads são entidades criadas pelo SO para possibilitar a execução de blocos de código que compartilham os recursos de um computador. Usando o conceito de contexto de execução, associado principalmente ao estado dos registradores do hardware na execução de um processo ou thread, o SO consegue promover a alternância dessas entidades no uso do(s) processador(es). O acesso a outros recursos, como unidades de armazenamento, é tipicamente oferecido por demanda.</p>

<p>De maneira geral, sabemos que o SO promove o compartilhamento eficiente do uso dos recursos sobrepondo as ações dos controladores de dispositivos nas operações de entrada e saída com a execução de instruções pelo(s) processador(es). Chamada de  multiprogramação, essa técnica evita que o processador fique ocioso aguardando a conclusão de uma transferência de dados realizada por um controlador de E/S. Para tanto, <span class="importante">o SO instrui o controlador a fazer a leitura ou escrita necessária e direciona o processador para a execução de código de outro processo ou thread prontos. Usando técnicas de acesso direto à memória (DMA), um controlador consegue transferir dados lidos de um dispositivo, através de um barramento, para a memória, e também enviar para um dispositivo dados lidos de áreas de memória usadas como buffers pelo SO</span>.</p>

<p class="importante">Outra forma de compartilhar o uso de um processador são as fatias de tempo. Um dispositivo de timer programável (programmable interrupt timer - PIT) presente na motherboard é usado pelo SO para a geração periódica de interrupções. Com essas interrupções, o SO retoma o controle da CPU em intervalos regulares, independentemente do fluxo de instruções do processo atual. Cabe ao SO determinar a frequência de ocorrência dessas interrupções, de acordo com a precisão dos eventos de temporização tratados.</p>

<p>Ao retomar o controle, além de verificar se há eventos agendados para tratar, o SO tem a chance de promover a alternância do uso deste processador. <span class="importante">Para tanto, fatias de tempo (processor time slices) são definidas para os processos na forma e um número de time ticks do gerador de interrupções periódicas. A cada interrupção do timer, um contador associado ao tempo de execução de um processo (ou thread) é decrementado</span>. Zerado o contador, isso significa o fim da fatia de tempo deste processo na CPU.</p>

<p class="destaque">Há várias questões, contudo, que tornam o uso de interrupções periódicas não apropriado. Inicialmente, a escolha da frequência das interrupções deve ser considerada. Intervalos mais curtos permitem maior precisão nos eventos de temporização mas, por outro lado, geram elevada sobrecarga com o processamento das interrupções. Além disso, interrupções periódicas impedem que o processador fique ocioso, mesmo quando não há nada efetivo a executar. Com isso, desperiça-se a chance de desativar o processador e economizar energia.</p>

<p class="duvida">Assim, o modelo de interrupção periódica tem dado lugar a tickless kernels. Nesses SOs, como ocorre com Linux, uma interrupção do timer é programada especificamente para o próximo evento. Embora isso gere um aumento na complexidade do tratamento de eventos de temporização, há possibilidade de economia significativa de energia.</p>

<p>Definido que um processo ou thread deve deixar a CPU momentaneamente, é preciso selecionar o próximo a ocupá-la. Essa seleção é chamada <b>escalonamento de curto prazo de processos</b>, ou simplesmente escalonamento (scheduling). Se processos podem deixar a CPU antes de suas conclusões para dar lugar a outros, tem-se um mecanismo de escalonamento denominado <b>preemptivo</b>. Em sistemas não preemptivos, um processo é executado até ser concluído ou até explicitamente liberar a CPU.</p>

<p>As chamada de sistema nice(2) e setpriority(2) permitem ajustar a prioridade estática de processos e grupos de processos.</p>

<pre><code>
  #include &ltunistd.h&gt
  int nice(int inc); // incrementa inc numeros na prioridade do processo (número nice)

  /*Quanto maior o valor nice, menor a prioridade*/

</code></pre>

<pre><code>
  #include &ltsys/time.h&gt
  #include &ltsys/resource.h&gt

  int getpriority(int which, id_t who);
  int setpriority(int which, id_t who, int prio);

</code></pre>

<p class="importante">Diferentes algoritmos de escalonamento podem ser implementados por um SO. O padrão POSIX, por exemplo, especifica as seguintes políticas para processos que não possuem restrições de tempo real:</p>

<ul>
  <li><b>SCHED_OTHER:</b> (padrão) round-robin time-sharing policy</li>
  <li><b>SCHED_BATCH:</b> para execução de processos no estilo "batch"</li>
  <li class="duvida"><b>SCHED_IDLE:</b> for running very low priority background jobs</li>
</ul>

<p>Para processos em tempo real:</p>

<ul>
  <li><b>SCHED_FIFO:</b> first-in, first-out policy</li>
  <li><b>SCHED_RR</b> round-robin policy</li>
</ul>

<p><span class="importante">Alguns atributos mantidos pelo SO para cada processo ou thread permitem ajustar seus escalonamentos</span>. Embora a política de escalonamento SCHED_OTHER seja associada por padrão a todo processo, a função <b>sched_setcheduler(2)</b>, por exemplo, permite alterar a política de escalonamento. Vale observar, contudo, que é preciso privilégio de super usuário para alterar a política de escalonamento para SCHED_FIFO ou SCHED_RR, que conferem propriedades de suporte a tempo real a um processo. A chamada <b>sched_getscheduler(2)</b> permite consultar parâmetros do escalonamento de um processo.</p>

<div class="ui yellow inverted segment">
  <h4>Anotações</h4>
  <p class="duvida">Migrate: o faz o controle de carga...</p>
  <p>Real time priority:</p>
  <p>Para um sistema de tempo real: o somatório dos tempos de cpu sob o periodo deve ser menor que o número de core.</p>
  <p>Completly fairness schedule (política do linux)</p>
  <p>Tempo de cpu/tempo de vida = fração de uso da CPU</p>
  <p>Quanto menor a fração do uso da CPU mais prioritário é o processo</p>
  <p class="duvida">Virtual (view?) Runtime</p>
  <p class="duvida">Valor de goodness* --> criação de 140 filas diferentes para cada valor de prioridade (algoritmo O(1)) (porém não evitava starvation) --> criação de mais um vetor de fila (active vs not active)</p>
</div>


<h3>Afinidade de CPUs</h3>

<p>O SO mantém informação sobre quais CPUs um processo pode ser executado.</p>

<pre><code>
  #include &ltsched.h&gt
  /* Configura uma máscara de bits para uma thread ou processo
  ** que indica em quais CPUs pode executar */

  int sched_setaffinity(pid_t pid, size_t cpusetsize, const cpu_set_t *mask);
  int sched_getaffinity(pid_t pid, size_t cpusetsize, cpu_set_t *mask);

</code></pre>

<p>Existem 3 níveis de cache: L1 e L2 para cada core e L3 pra o processador (compartilhado pelos cores).O SO mantém filas separadas para cada core do processador para que o cache de cada core possa ser utilizado ao máximo.</p>

<pre><code>#include &ltunistd.h&gt
  /*Recupera informações sobre o sistema em tempo de execução*/
  long sysconf(int name);
</code></pre>

<h2>Consumo de Recursos</h2>

<p>O SO aloca recursos para a execução de cada processo e thread, mas mantém registros das contabilizações de uso desses recursos para cada processo.</p>

<p>Toda vez que uma  CPU é redirecionada da execução de um processo para o SO, o SO contabiliza quanto tempo este processo passou na CPU (user time) tendo suas instruções executadas. O tempo gasto pelo SO prestando serviços (system time) para um processo também é contabilizado. Quando o processo deixa a CPU, o SO salva os valores coletados no descritor do processo.</p>

<p> Informações sobre o tamanho máximo ocupado na memória e sobre o consumo de outros recursos também são mantidas pelo SO. Seja para monitoração ou análise do processo atual (RUSAGE_SELF), dos seus processos filhos (RUSAGE_CHILDREN) ou da thread corrente (RUSAGE_THREAD), é possível consultar essas informações usando a chamada de sistema getrusage(2).</p>

<pre><code>#include &ltsys/time.h&gt
  #include &ltsys/resource.h&gt

  // Recupera informações sobre o uso de recursos de who
  int getrusage(int who, struct rusage *usage);

  struct rusage {
    struct timeval ru_utime; /* user time used */
    struct timeval ru_stime; /* system time used */
    long ru_maxrss; /* max resident set size */
    long ru_ixrss; /* integral shared text memory size */
    long ru_idrss; /* integral unshared data size */
    long ru_isrss; /* integral unshared stack size */
    long ru_minflt; /* page reclaims */
    long ru_majflt; /* page faults */
    long ru_nswap; /* swaps */
    long ru_inblock; /* block input operations */
    long ru_oublock; /* block output operations */
    long ru_msgsnd; /* messages sent */
    long ru_msgrcv; /* messages received */
    long ru_nsignals; /* signals received */
    long ru_nvcsw; /* voluntary context switches */
    long ru_nivcsw; /* involuntary context switches */
  };
</code></pre>

<div class="ui red inverted segment">
  <h4>Como calcular o user time?</h4>
  <p>User time é o tempo em que o processo ficou executando na CPU. Para calculá-lo podemos, todas vez que terminar o time slice do processo (ou simplesmente quando houver a troca de contexto), incrementa o user time com o tempo decorrido da restauração do contexto atual ao tempo de troca.</p>

  <h4>Como calcular o system time?</h4>
  <p>System time é o tempo em que o SO ficou prestando serviço para esse processo (realizando chamadas de sistema), ou seja, em que o processo ficou sendo executado em modo kernel. Para calcular, basta somar ao system time o tempo de cada systemcall realizada.</p>
</div>

<h4>Como calcular o consumo de recurso em um trecho de código?</h4>
<pre><code class="c">
  struct timeval inic,fim;
  struct rusage r1, r2;

  // determina o instante atual (gettimeofday)
  // int gettimeofday(struct timeval *tv, struct timezone *tz);
  gettimeofday(&inic, 0);

  // determina quanto foi consumido de recursos até aqui (getrusage)
  getrusage(RUSAGE_SELF, &r1);

  // aqui entra a função cujo tempo se quer avaliar

  // determina o instante atual (gettimeofday)
  gettimeofday(&fim,0); // tempo decorrido

  // determina quanto foi consumido de recursos até aqui (getrusage)
  getrusage(RUSAGE_SELF, &r2);

  // diferença entre r2 e r1 (ru_utime e ru_stime) indica consumo de recursos para o trecho de código
  // diferença entre fim e inic inica o tempo decorrido (elapsed time)
</code></pre>

<h3>Limites</h3>
<p>O SO pode limitar o consumo de recursos por um processo e seus descendentes.</p>

<pre><code>#include &ltsys/time.h&gt
  #include &ltsys/resource.h&gt

  int getrlimit(int resource, struct rlimit *rlim);
  int setrlimit(int resource, const struct rlimit *rlim);</code></pre>

  struct rlimit {
    rlim_t rlim_cur;  /* Soft limit */
    rlim_t rlim_max;  /* Hard limit (ceiling for rlim_cur) */
  };

<p class="duvida">ulimit -a e ulimit -t</p>

<h2>Tratamento de Sinais</h2>

<p class="importante">Sinais são um mecanismo de notificações para processos (ou grupo se processos), comumente associados a eventos ocorridos durante suas execuções. Esse sinais são enviados de forma implícita ou explícita (enviando o sinal através do chamada de sistema kill(2)).</p>

<p>De acordo com o padrão POSIX, há 2 grupos de sinais:</p>

<ul>
  <li><b class="importante">Reliable signals:</b> são os sinais normais. Estão associados a eventos pré-definidos e têm números associados de 1 a 31 (não são cumulativos, de forma que pode haver apenas uma pendência de cada sinal);</li>
  <li><b class="importante">Real-time signals:</b> definidos pelas macros SIGRTMIN e SIGRTMAX, podem ser gerados de acordo com a lógica do programa que os utiliza (pode haver várias ocorrências pendentes).</li>
</ul>

<p class="importante">Para poder tratar o envio e recebimento de sinais, o SO mantém <a href="http://elixir.free-electrons.com/linux/latest/source/include/linux/sched/signal.h#L78">estruturas de dados de controle de sinais</a> para cada processo. Essas estruturas permitem que um processo ignore o recebimento de um sinal específico, que seja instalada uma rotina de tratamento para um sinal, ou que o recebimento de um sinal seja bloqueado explicitamente (apenas os sinais SIGKILL e SIGSTOP não podem ser capturados, ignorados ou bloqueados)</p>

<p>Sinais que não são tratados por um processo possuem ações pré-definidas pelo SO. Dependendo do sinal, essas ações podem terminar a execução do processo, terminar a execução e gerar um arquivo com a imagem do processo na memória (core dump), ou simplesmente ignorar.</p>

<div class="ui red inverted segment">
  <h4>Core Dump</h4>
  <p>O core dump é um arquivo em disco contendo um imagem da memória do processo no momento de sua terminação.</p>
</div>

<p>De acordo com os padrões POSIX, <b>threads</b> de um processo compartilham o tratamento de sinais do processo ao qual estão associadas, mas cada uma pode ter sua própria máscara de recebimento de sinais. Na programação com threads POSIX é possível ainda enviar sinais para threads específicas de um processo, usando a função <b>pthread_kill(3)</b>, que no linux é implementada sobre a chamada de sistema <b>tgkill(2)</b>. A função <b>raise(3)</b> permite enviar um sinal para a thread corrente. Para o envio de sinais de tempo real para threads é possível usar a função <b>sigqueue(3)</b></p>.

<p>É possível bloquear a thread (ou processo) atual à espera de um sinal. A chamada de sistema <b>pause(2)</b> bloqueia o processo (ou thread) atual à espera do recebimento de algum sinal. O mesmo ocorre com a chamada <b>sigsuspend(2)</b>, que permite esperar pelo recebimento de um sinal ao mesmo tempo em que uma máscara temporária bloqueia sinais não desejados.</p>

<p class="importante">O recebimento efetivo de um sinal ocorre quando o processo já teve seu contexto restaurado depois de ter sido selecionado para execução pelo escalonador. Isso corre porque é preciso ajustar o contexto do processo alvo, restaurando sua tabela de páginas e ponteiros de código e pilha, além de retornar o processador ao user mode antes de executar uma rotina de tratamento associada. Assim, exceto pelos sinais SIGKILL E SIGSTOP, os demais sinais, que não foram ignorados por um processo, apenas são marcados como pendentes de envio.</p>

<div class="ui inverted segment">
  O tratamento apropriado vai ocorrer apenas quando o processo voltar à execução, com contexto restaurado, mas antes de retornar as atividades interrompidas.
</div>

<p>Como a entrega de sinais é assíncrona, é possível haver reentrância de código usado na função de tratamento de sinal com outras atividades sendo realizadas no fluxo normal de execuçao do processo e de suas threads. Assim, há a preocupação com essa reentrância de código e com segurança devido ao sincronismo <b>(asynchronous safety)</b>. O código de tratamento de um sinal deve poder ser interrompido a qualquer momento sem causar estados inconsistentes no processo.</p>

<hr>

<p>Como o SO acha um processo? Cada processo está ligado a uma lista com todos os processos e outra com os processos no estado atual do processo.</p>

<p>ps s: mostra o status de sinais</p>

<p>Há diferença no tratamento de exceção (o incremento de PC pode não ser válido, por tanto decrementa 1, ou seja, volta para instrução onde ocorreu a exceção) e interrupção</p>

<p>Segmento BSS</p>

<p>O tratamento de sinais de processo é realizado na restauração do contexto do processo, antes de continuar com a execução normal.</p>
